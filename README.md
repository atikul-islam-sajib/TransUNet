# **ğŸš€ TransUNet - Transformer-Based U-Net for Medical Image Segmentation**

**TransUNet** is an advanced **hybrid deep learning model** that combines **CNNs (Convolutional Neural Networks)** and **Transformers** to improve segmentation accuracy in medical imaging. The model enhances **U-Net** by integrating **self-attention mechanisms**, making it more efficient for complex segmentation tasks.

---

## **ğŸ“Œ Key Features**
âœ… Hybrid **CNN + Transformer** architecture for robust segmentation  
âœ… Supports multiple optimizers: **Adam, AdamW, SGD**  
âœ… Configurable loss functions: **BCE, Focal, Tversky**  
âœ… Multi-device support: **CPU, GPU, Apple M1/M2 (`mps`)**  
âœ… Automatic **dataset handling, model training, and evaluation**  
âœ… Saves **segmentation masks** and **best-performing model checkpoints**  

---

## **ğŸ“Œ Model Architecture**
The **TransUNet** model follows a two-stage approach:  
1ï¸âƒ£ **CNN Encoder** - Extracts local spatial features  
2ï¸âƒ£ **Transformer Block** - Captures **global dependencies**  
3ï¸âƒ£ **Decoder** - Combines CNN and Transformer outputs for segmentation  

```
Input Image (H x W x C)
       â”‚
       â–¼
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ CNN Encoder â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   (Extracts feature maps)
       â”‚
       â–¼
-----> Transformer Block ----->   (Captures long-range dependencies)
       â”‚
       â–¼
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Decoder (UpSampling + Skip Connections) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
       â”‚
       â–¼
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Segmentation Mask (Output) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

---

## **ğŸ“Œ Installation**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/atikul-islam-sajib/TransUNet.git
cd TransUNet
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ (Optional) Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

---

## **ğŸ“Œ Configuration - `config.yaml`**
Before running training or testing, modify `config.yaml` to set paths, model parameters, and training options.

### **ğŸ”¹ Example Configuration: Training Settings**
```yaml
trainer:
  epochs: 100
  lr: 0.0001
  optimizer: "AdamW"
  device: "cuda"  # Change to "cpu" for CPU training
```

### **ğŸ”¹ Example Configuration: Changing Optimizer**
```yaml
optimizer: "SGD"
```

### **ğŸ”¹ Example Configuration: Dataset Paths**
```yaml
dataloader:
  image_path: "./data/raw/dataset.zip"
  batch_size: 8
  image_size: 128
  split_size: 0.30
```

---

## **ğŸ“Œ Running Training & Testing**
| **Process**      | **Command**                     | **Description** |
|------------------|---------------------------------|-----------------|
| **Train Model**  | `python src/cli.py --train`     | Starts model training using `config.yaml` |
| **Test Model**   | `python src/cli.py --test`      | Runs evaluation on test data |
| **Change Optimizer** | Edit `config.yaml`          | Supports `"SGD"`, `"Adam"`, `"AdamW"` |

---

## **ğŸ“Œ Viewing Results**
### **ğŸ”¹ Model Checkpoints**
Trained models are saved in:
```bash
./artifacts/checkpoints/train_models/
```

### **ğŸ”¹ Best Model**
The best-performing model is saved in:
```bash
./artifacts/checkpoints/best_model/
```

### **ğŸ”¹ Test Predictions**
Generated segmentation masks are saved in:
```bash
./artifacts/outputs/test_image/
```

---

## **ğŸ“Œ TransUNet Workflow**
```
1ï¸âƒ£ Load Dataset  ----->  2ï¸âƒ£ Train Model  ----->  3ï¸âƒ£ Evaluate  ----->  4ï¸âƒ£ Generate Predictions
```

---

## **ğŸ“Œ Citation**
If you use this repository, please consider citing:
```
@article{chen2021transunet,
  title={TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation},
  author={Chen, Jieneng and Lu, Yutong and Yu, Qihang and others},
  journal={arXiv preprint arXiv:2102.04306},
  year={2021}
}
```

---

## **ğŸ“Œ License**
This project is **open-source** and available under the **MIT License**.

---

# **ğŸ”¥ Ready to Get Started?**
- Modify `config.yaml` for your setup.  
- Run **training** with: `python src/cli.py --train`  
- Run **testing** with: `python src/cli.py --test`  

ğŸš€ **Happy Training & Testing with TransUNet!** ğŸš€  