{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔹 Step 1: Clone the TransUNet Repository**\n",
    "First, we need to clone the repository to access the project files.\n",
    "\n",
    "```python\n",
    "# Clone the TransUNet repository from GitHub\n",
    "!git clone https://github.com/atikul-islam-sajib/TransUNet.git\n",
    "\n",
    "# Change directory to the cloned folder\n",
    "%cd TransUNet\n",
    "```\n",
    "\n",
    "🔹 **Explanation:**  \n",
    "- `git clone` downloads the entire repository to your local machine.  \n",
    "- `%cd TransUNet` moves into the cloned project folder.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Step 2: Install Dependencies**\n",
    "To run the project, we need to install all required packages.\n",
    "\n",
    "```python\n",
    "# Install required Python libraries\n",
    "!pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "🔹 **Explanation:**  \n",
    "- The `requirements.txt` file contains all necessary dependencies.  \n",
    "- This command ensures your environment has the required libraries.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Step 3: Set Up Virtual Environment (Optional)**\n",
    "It's good practice to use a virtual environment to avoid conflicts.\n",
    "\n",
    "```python\n",
    "# Create a virtual environment (optional)\n",
    "!python -m venv venv  \n",
    "\n",
    "# Activate the virtual environment (Linux/macOS)\n",
    "!source venv/bin/activate  \n",
    "\n",
    "# For Windows, use:\n",
    "# !venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "🔹 **Explanation:**  \n",
    "- Virtual environments keep dependencies isolated.  \n",
    "- Activate it before running the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/atikul-islam-sajib/TransUNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd TransUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📌 How to Use the `config.yaml` File?**\n",
    "This configuration file **controls all key settings** for dataset paths, model parameters, training options, and inference settings.  \n",
    "Users **should update this file** before running training or testing.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Explanation of Each Section**\n",
    "\n",
    "### **1️⃣ Artifacts Section (File Paths)**\n",
    "```yaml\n",
    "artifacts:\n",
    "  raw_data_path: \"./data/raw/\"\n",
    "  processed_data_path: \"./data/processed/\"\n",
    "  files_path: \"./artifacts/files/\"\n",
    "  train_models: \"./artifacts/checkpoints/train_models/\"\n",
    "  best_model: \"./artifacts/checkpoints/best_model/\"\n",
    "  metrics_path: \"./artifacts/metrics/\"\n",
    "  train_images: \"./artifacts/outputs/train_images/\"\n",
    "  test_image: \"./artifacts/outputs/test_image/\"\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- Defines **storage paths** for raw data, processed data, model checkpoints, and output images.  \n",
    "- **Users should update paths** if they want to store files in a different location.\n",
    "---\n",
    "\n",
    "### **2️⃣ Dataloader Section (Dataset Settings)**\n",
    "```yaml\n",
    "dataloader:\n",
    "  image_path: \"./data/raw/dataset.zip\"\n",
    "  image_channels: 3\n",
    "  image_size: 128\n",
    "  batch_size: 8\n",
    "  split_size: 0.30\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- **`image_path`** → Location of the dataset (can be a `.zip` file).  \n",
    "- **`image_channels`** → Number of image channels (e.g., `3` for RGB, `1` for grayscale).  \n",
    "- **`image_size`** → Image resolution for training (`128x128`).  \n",
    "- **`batch_size`** → Number of images per training batch.  \n",
    "- **`split_size`** → Percentage of data reserved for validation (`30%` means 70% training, 30% validation).  \n",
    "---\n",
    "\n",
    "### **3️⃣ TransUNet Model Configuration**\n",
    "```yaml\n",
    "TransUNet:\n",
    "  nheads: 4\n",
    "  num_layers: 4\n",
    "  dim_feedforward: 512\n",
    "  dropout: 0.3\n",
    "  activation: \"gelu\"\n",
    "  layer_norm_eps: 1e-05\n",
    "  bias: False\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- **Defines the architecture** of the Transformer-based UNet (`TransUNet`).  \n",
    "- **`nheads`** → Number of attention heads.  \n",
    "- **`num_layers`** → Number of transformer encoder layers.  \n",
    "- **`dim_feedforward`** → Hidden layer size in the feedforward network.  \n",
    "- **`dropout`** → Dropout probability (reduces overfitting).  \n",
    "- **`activation`** → Activation function (`relu`, `gelu`, etc.).  \n",
    "- **`bias`** → Whether to use bias in layers (`True` or `False`).  \n",
    "---\n",
    "\n",
    "### **4️⃣ Trainer Section (Training Settings)**\n",
    "```yaml\n",
    "trainer:\n",
    "  epochs: 100\n",
    "  lr: 0.0001\n",
    "  optimizer: \"AdamW\"\n",
    "  optimizers:\n",
    "    Adam: \n",
    "      beta1: 0.9\n",
    "      beta2: 0.999\n",
    "      weight_decay: 0.0001\n",
    "    SGD: \n",
    "      momentum: 0.95\n",
    "      weight_decay: 0.0\n",
    "    AdamW:\n",
    "      beta1: 0.9\n",
    "      beta2: 0.999\n",
    "      weight_decay: 0.0001\n",
    "  loss: \n",
    "    type: \"bce\"\n",
    "    loss_smooth: 1e-06\n",
    "    alpha_focal: 0.75\n",
    "    gamma_focal: 2\n",
    "    alpha_tversky: 0.75\n",
    "    beta_tversky: 0.5\n",
    "  l1_regularization: False\n",
    "  elastic_net_regularization: False\n",
    "  verbose: True\n",
    "  device: \"mps\"\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- **`epochs`** → Number of training epochs.  \n",
    "- **`lr`** → Learning rate for optimization.  \n",
    "- **`optimizer`** → Which optimizer to use (`Adam`, `AdamW`, or `SGD`).  \n",
    "- **`optimizers`** → Defines **hyperparameters** for each optimizer.  \n",
    "- **`loss`** → Loss function settings (`bce`, `focal`, or `tversky`).  \n",
    "- **`device`** → Hardware (`cuda`, `cpu`, or `mps` for Apple M1/M2).  \n",
    "---\n",
    "\n",
    "### **5️⃣ Tester Section (Testing Configuration)**\n",
    "```yaml\n",
    "tester:\n",
    "  dataset: \"test\"\n",
    "  device: \"mps\"\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- **`dataset`** → Defines the dataset used for testing.  \n",
    "- **`device`** → Hardware for testing (`cuda`, `cpu`, or `mps`).  \n",
    "---\n",
    "\n",
    "### **6️⃣ Inference Section (Prediction Settings)**\n",
    "```yaml\n",
    "inference:\n",
    "  image: \"./artifacts/data/processed...\"\n",
    "```\n",
    "🔹 **What this does?**  \n",
    "- Defines the **path to an image** for making predictions.  \n",
    "---\n",
    "\n",
    "## **🎯 Summary of Key Edits**\n",
    "| Section  | Purpose  | Example Change  |\n",
    "|---|---|---|\n",
    "| **Artifacts**  | Change storage paths | `best_model: \"./my_models/best_model.pth\"` |\n",
    "| **Dataloader**  | Change dataset path | `image_path: \"./new_dataset.zip\"` |\n",
    "| **TransUNet**  | Modify model size | `num_layers: 6, dropout: 0.5` |\n",
    "| **Trainer**  | Change training settings | `optimizer: \"SGD\", epochs: 50` |\n",
    "| **Tester**  | Change test device | `device: \"cpu\"` |\n",
    "| **Inference**  | Set test image | `image: \"./test/sample.jpg\"` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat config.yml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **🔹 Run Training**\n",
    "To train the model using the configurations set in `config.yaml`, run:\n",
    "\n",
    "```bash\n",
    "python src/cli.py --train\n",
    "```\n",
    "\n",
    "#### **🔹 What This Does:**\n",
    "- Loads the dataset and preprocesses it.\n",
    "- Initializes the **TransUNet** model with the specified hyperparameters.\n",
    "- Trains the model for the number of **epochs** defined in `config.yaml`.\n",
    "- Saves training history, checkpoints, and metrics in the **artifacts folder**.\n",
    "\n",
    "---\n",
    "\n",
    "### **🔹 Run Testing**\n",
    "Once training is completed, test the trained model using:\n",
    "\n",
    "```bash\n",
    "python src/cli.py --test\n",
    "```\n",
    "\n",
    "#### **🔹 What This Does:**\n",
    "- Loads the best trained model from `artifacts/checkpoints/best_model/`.\n",
    "- Evaluates the model on the test dataset.\n",
    "- Generates predicted segmentation masks for test images.\n",
    "- Saves output images in `artifacts/outputs/test_image/`.\n",
    "\n",
    "---\n",
    "\n",
    "### **📌 Checking Outputs**\n",
    "After training and testing:\n",
    "- The **trained model** is saved in:  \n",
    "  ```bash\n",
    "  ./artifacts/checkpoints/train_models/\n",
    "  ```\n",
    "- The **best model** (selected based on performance) is saved in:  \n",
    "  ```bash\n",
    "  ./artifacts/checkpoints/best_model/\n",
    "  ```\n",
    "- **Predicted test images** are stored in:  \n",
    "  ```bash\n",
    "  ./artifacts/outputs/test_image/\n",
    "  ```\n",
    "---\n",
    "\n",
    "### **🚀 Summary**\n",
    "| **Command**  | **Function**  |\n",
    "|---|---|\n",
    "| `python src/cli.py --train`  | Starts model training based on `config.yaml`  |\n",
    "| `python src/cli.py --test`  | Runs model testing and saves predictions  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cli.py --train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cli.py --test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
